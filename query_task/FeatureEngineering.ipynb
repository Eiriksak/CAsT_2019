{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows every step of our query expansion algorithm. We will also evaluate how different parts performs both on training data ans unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import spacy\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "import utils\n",
    "import spacy\n",
    "import evaluator\n",
    "from evaluator import train_topics, train_qrels, test_topics, test_qrels\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(http_auth=(os.environ['ES_USER'], os.environ['ES_PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pos_vocab(X):\n",
    "    pos_vocab = []\n",
    "    for topic in X:\n",
    "        for turn in topic['turn']:\n",
    "            doc = nlp(turn['raw_utterance'])\n",
    "            for token in doc:\n",
    "                if token.pos_ not in pos_vocab:\n",
    "                    pos_vocab.append(token.pos_)\n",
    "    return pos_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'AUX',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'PART',\n",
       " 'PUNCT',\n",
       " 'ADJ',\n",
       " 'VERB',\n",
       " 'NUM',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'CCONJ',\n",
       " 'ADV',\n",
       " 'SPACE',\n",
       " 'SCONJ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_vocab = init_pos_vocab(train_topics)\n",
    "pos_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector representation of POS tags in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_parser(text, pos_vocab):\n",
    "    doc = nlp(text)\n",
    "    tags = []\n",
    "    res = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in pos_vocab:\n",
    "            tags.append(token.pos_)\n",
    "            res.append(token.text)\n",
    "    return res, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train_topics[0]['turn'][0]['raw_utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is a physician's assistant\n"
     ]
    }
   ],
   "source": [
    "q = evaluator.analyzer(es, t, 'trec2019_stem')\n",
    "q = ' '.join(q)\n",
    "print(q)\n",
    "txt, pos = pos_parser(q, pos_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_counts(pos_list, pos_vocab):\n",
    "        return [pos_list.count(i) for i in pos_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos_counts(pos, pos_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate POS vectors for all turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(pos):\n",
    "    num = sum([1 for tag in pos if tag in ['NOUN', 'PROPN']])\n",
    "    if num > 2:\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat1 = {}\n",
    "cat2 = {} # Need context\n",
    "index = {}\n",
    "for topic in train_topics:\n",
    "    for turn in topic['turn']:\n",
    "        qid = turn['qid']\n",
    "        _qrels = utils.get_qrels(qid, train_qrels)\n",
    "        q = ' '.join(evaluator.analyzer(es, turn['raw_utterance'], 'trec2019_stem'))\n",
    "        index[qid] = {'text': q}\n",
    "        if not _qrels: # Only include turns with labeled relevancy\n",
    "            continue\n",
    "        txt, pos = pos_parser(q, pos_vocab)\n",
    "        pos_vec = get_pos_counts(pos, pos_vocab)\n",
    "        cat = get_category(pos)\n",
    "        if turn['number'] == 1 or cat==1:\n",
    "            cat1[qid] = {'pos_vec': pos_vec}\n",
    "        else:\n",
    "            cat2[qid] = {'pos_vec': pos_vec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_category(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access POS vector from category 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_vec': [1, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat1['1_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access POS vector from category 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_vec': [1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2['1_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access query from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'what are the educational requirements required to become one'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index['1_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category 1\n",
    "## Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):   \n",
    "    return np.sqrt(np.sum((np.array(x) - np.array(y)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1_vec = [i['pos_vec'] for _, i in cat1.items()]\n",
    "cat2_vec = [i['pos_vec'] for _, i in cat2.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(pos_vec, cat, qid='None', k=1):\n",
    "    dists = {}\n",
    "    for key, v in cat.items():\n",
    "        if key != qid:\n",
    "            dist = euclidean_distance(v['pos_vec'], pos_vec)\n",
    "            dists[key] = dist\n",
    "    dists = {key: v for key, v in sorted(dists.items(), key=lambda item: item[1])}\n",
    "    return {key:dists[key] for key in list(dists.keys())[:k]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: what is a physician's assistant\n",
      "3 nearest neighbors\n",
      "what are the main breeds of goat\n",
      "what was the neolithic revolution\n",
      "what are the different types of macromolecules\n"
     ]
    }
   ],
   "source": [
    "q = ' '.join(evaluator.analyzer(es, index['1_1']['text'], 'trec2019_stem'))\n",
    "_, pos = pos_parser(q, pos_vocab)\n",
    "nb = knn(get_pos_counts(pos, pos_vocab), cat1, '1_1', 3)\n",
    "print(f'Original: {index[\"1_1\"][\"text\"]}')\n",
    "print(\"3 nearest neighbors\")\n",
    "for n in nb:\n",
    "    print(index[n][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the nearest neighbor queries are pretty similar to the original one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse engineer perfect query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_res(qid, qrels):\n",
    "    \"\"\"Only return those with relevancy above 1\"\"\"\n",
    "    _qrels = utils.get_qrels(qid, qrels)\n",
    "    if not _qrels:\n",
    "        return None\n",
    "    ground_truth = utils.get_ground_truth(_qrels)\n",
    "    return {k: v for k, v in sorted(ground_truth.items(), key=lambda item: item[1], reverse=True) if v>0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MARCO_955948': 2,\n",
       " 'MARCO_6203672': 2,\n",
       " 'MARCO_955945': 2,\n",
       " 'MARCO_6203671': 2,\n",
       " 'MARCO_5692406': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid = '1_1'\n",
    "top_res = get_top_res(qid, train_qrels)\n",
    "top_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(text, pos_vocab, k=20):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if token.pos_ in pos_vocab]\n",
    "    tokens = Counter(tokens).most_common(k) # [(word, count), (word, count)..] descending order by count\n",
    "    return tokens\n",
    "\n",
    "def get_kw_stats(top_res, es, index, pos_vocab):\n",
    "    res = {}\n",
    "    kw_count = {}\n",
    "    for doc_id, relevance in top_res.items():\n",
    "        search_res = es.get(index=index, id=doc_id)\n",
    "        doc = search_res['_source']['body']\n",
    "        doc = ' '.join(evaluator.analyzer(es, doc, index))\n",
    "        keywords = get_keywords(doc, pos_vocab)\n",
    "        for kw in keywords:\n",
    "            if kw[0] not in kw_count:\n",
    "                kw_count[kw[0]] = 0\n",
    "            kw_count[kw[0]] +=  kw[1] # 2 in relevancy more important\n",
    "        res[doc_id] = {'doc': doc, 'keywords': keywords}\n",
    "    return res, kw_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, kw_count = get_kw_stats(top_res, es, 'trec2019_stem', pos_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': 'physician assistants work under the supervision of a physician or surgeon however their specific duties and the extent to which they must be supervised differ from state to state physician assistants work in all areas of medicine including primary care and family medicine emergency medicine and psychiatry.the work of physician assistants depends in large part on their specialty and what their supervising physician needs them to do.for example a physician assistant working in surgery may close incisions and provide care before and after the operation.he work of physician assistants depends in large part on their specialty and what their supervising physician needs them to do for example a physician assistant working in surgery may close incisions and provide care before and after the operation',\n",
       " 'keywords': [('physician', 9),\n",
       "  ('and', 9),\n",
       "  ('their', 5),\n",
       "  ('in', 5),\n",
       "  ('assistants', 4),\n",
       "  ('work', 4),\n",
       "  ('the', 4),\n",
       "  ('of', 4),\n",
       "  ('to', 4),\n",
       "  ('a', 3),\n",
       "  ('medicine', 3),\n",
       "  ('care', 3),\n",
       "  ('state', 2),\n",
       "  ('depends', 2),\n",
       "  ('large', 2),\n",
       "  ('part', 2),\n",
       "  ('on', 2),\n",
       "  ('specialty', 2),\n",
       "  ('what', 2),\n",
       "  ('supervising', 2)]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MARCO_955948']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'physician': 34, 'and': 32, 'their': 17, 'in': 14, 'assistants': 13, 'work': 7, 'the': 11, 'of': 11, 'to': 8, 'a': 16, 'medicine': 7, 'care': 6, 'state': 2, 'depends': 4, 'large': 4, 'part': 4, 'on': 8, 'specialty': 4, 'what': 6, 'supervising': 4, 'needs': 2, 'them': 2, 'do': 2, 'provide': 4, 'also': 2, 'known': 2, 'as': 3, 'pas': 1, 'practice': 1, 'team': 1, 'diagnostic': 1, 'therapeutic': 1, 'preventive': 1, 'healthcare': 1, 'services': 1, 'delegated': 1, 'by': 1, 'pa': 5, 'assistant': 5, 'is': 4, 'medical': 3, 'c': 3, 'md': 2, 'doctor': 2, 'an': 2, \"'s\": 2, 'are': 2, 'fully': 2, 'qualified': 2, 'physicians': 2, 'graduated': 2, 'from': 2, 'accredited': 2}\n"
     ]
    }
   ],
   "source": [
    "topk_kw = {key:kw_count[key] for key in list(kw_count.keys())}\n",
    "print(topk_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what is a physician's assistant\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index[qid]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_score(q, qid, qrels, es, index, size=100):\n",
    "    search_results, system_ranking, ground_truth = evaluator.get_search_data(q,\n",
    "                                                               qid,\n",
    "                                                               qrels,\n",
    "                                                               es,\n",
    "                                                               index,\n",
    "                                                               size\n",
    "                                                              )\n",
    "    return utils.ndcg(system_ranking, ground_truth, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original score was: 0.0\n",
      "\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known', 'pas', 'practice', 'team', 'diagnostic', 'therapeutic', 'preventive', 'healthcare']\n",
      "20  score  0.6199062332840657\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known', 'pas', 'practice', 'team', 'diagnostic', 'therapeutic', 'preventive']\n",
      "19  score  0.6199062332840657\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known', 'pas', 'practice', 'team', 'diagnostic', 'therapeutic']\n",
      "18  score  0.7601875334318686\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known', 'pas', 'practice', 'team', 'diagnostic']\n",
      "17  score  1.0\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known', 'pas', 'practice', 'team']\n",
      "16  score  1.0\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known', 'pas', 'practice']\n",
      "15  score  1.0\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known', 'pas']\n",
      "14  score  1.0\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known']\n",
      "13  score  1.0\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide']\n",
      "12  score  0.7601875334318686\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs']\n",
      "11  score  0.7601875334318686\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising']\n",
      "10  score  0.7601875334318686\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty']\n",
      "9  score  0.7601875334318686\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large']\n",
      "8  score  0.7601875334318686\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends']\n",
      "7  score  0.7601875334318686\n",
      "['physician', 'assistants', 'work', 'medicine', 'care', 'state']\n",
      "6  score  0.6199062332840657\n",
      "['physician', 'assistants', 'work', 'medicine', 'care']\n",
      "5  score  0.3800937667159343\n",
      "['physician', 'assistants', 'work', 'medicine']\n",
      "4  score  0.3800937667159343\n",
      "['physician', 'assistants', 'work']\n",
      "3  score  0.7601875334318686\n",
      "['physician', 'assistants']\n",
      "2  score  0.0\n",
      "\n",
      "Top query: {'score': 1.0, 'q': ['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known']}\n"
     ]
    }
   ],
   "source": [
    "base_score = get_base_score(index[qid]['text'], qid, train_qrels, es, 'trec2019_stem')\n",
    "print(f'Original score was: {base_score}\\n')\n",
    "last_query = []\n",
    "top_query = {'score': 0, 'q': None}\n",
    "for s in range(20, 1, -1):\n",
    "    query = [i for i in topk_kw if i not in nlp.Defaults.stop_words][:s] # Top s keywords\n",
    "    if query == last_query:\n",
    "        continue\n",
    "    last_query = query\n",
    "    print(query)\n",
    "    search_results, system_ranking, ground_truth = evaluator.get_search_data(query,\n",
    "                                                                   qid,\n",
    "                                                                   train_qrels,\n",
    "                                                                   es,\n",
    "                                                                   'trec2019_stem',\n",
    "                                                                   100\n",
    "                                                                  )\n",
    "    if system_ranking is None:\n",
    "        continue\n",
    "\n",
    "    score = utils.ndcg(system_ranking, ground_truth, k=3)\n",
    "    if score >= top_query['score']:\n",
    "        top_query = {'score': score, 'q': query}\n",
    "    print(s, \" score \", score)\n",
    "print(f'\\nTop query: {top_query}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze which POS tags were used in the \"perfect\" query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOUN', 'NOUN', 'PROPN', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB']\n",
      "Unique:  {'ADJ', 'NOUN', 'VERB', 'PROPN'}\n"
     ]
    }
   ],
   "source": [
    "q = ' '.join([i for i in top_query['q']])\n",
    "txt, pos =  pos_parser(q, pos_vocab)\n",
    "print(pos)\n",
    "print(\"Unique: \", set(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 8, 0, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos_counts(pos, pos_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that some pos tags are more important than others, especially NOUN tags. We can use this information to filter out new queries. Reverse engineer all queries in category 1 and store the results in the cat1 dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perfect_query(qid, qrels, es, index, index_name, pos_vocab, size=100):\n",
    "    base_score = get_base_score(index[qid]['text'], qid, qrels, es, index_name)\n",
    "    top_res = get_top_res(qid, qrels)        \n",
    "    _, kw_count = get_kw_stats(top_res, es, index_name, pos_vocab)\n",
    "    topk_kw = {key:kw_count[key] for key in list(kw_count.keys())}\n",
    "    last_query = []\n",
    "    top_query = {'score': 0, 'base_score': base_score ,'q': None}\n",
    "    for s in range(20, 1, -1):\n",
    "        query = [i for i in topk_kw if i not in nlp.Defaults.stop_words][:s] # Top s keywords\n",
    "        if query == last_query:\n",
    "            continue\n",
    "        query = evaluator.analyzer(es, ' '.join(query), 'trec2019_stem')\n",
    "        last_query = query\n",
    "        search_results, system_ranking, ground_truth = evaluator.get_search_data(query,\n",
    "                                                                       qid,\n",
    "                                                                       qrels,\n",
    "                                                                       es,\n",
    "                                                                       index_name,\n",
    "                                                                       size\n",
    "                                                                      )\n",
    "        if system_ranking is None:\n",
    "            continue\n",
    "\n",
    "        score = utils.ndcg(system_ranking, ground_truth, k=3)\n",
    "        if score >= top_query['score']:\n",
    "            top_query = {'score': score, 'base_score': base_score, 'q': query}\n",
    "            \n",
    "    q = ' '.join([i for i in top_query['q']])\n",
    "    txt, pos =  pos_parser(q, pos_vocab)\n",
    "    pos_vec = get_pos_counts(pos, pos_vocab)\n",
    "    top_query['pos_vec'] = pos_vec\n",
    "    top_query['pos'] = set(pos)\n",
    "    return top_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.0,\n",
       " 'base_score': 0.0,\n",
       " 'q': ['physician',\n",
       "  'assistants',\n",
       "  'work',\n",
       "  'medicine',\n",
       "  'care',\n",
       "  'state',\n",
       "  'depends',\n",
       "  'large',\n",
       "  'specialty',\n",
       "  'supervising',\n",
       "  'needs',\n",
       "  'provide',\n",
       "  'known'],\n",
       " 'pos_vec': [0, 0, 0, 8, 0, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'pos': {'ADJ', 'NOUN', 'PROPN', 'VERB'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_perfect_query('1_1', train_qrels, es, index, 'trec2019_stem', pos_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 1.0, 'base_score': 0.0, 'q': ['physician', 'assistants', 'work', 'medicine', 'care', 'state', 'depends', 'large', 'specialty', 'supervising', 'needs', 'provide', 'known'], 'pos_vec': [0, 0, 0, 8, 0, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB', 'PROPN'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.0, 'q': ['physician', 'starting', 'salary', 'assistantâ', 's', 'companies'], 'pos_vec': [0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], 'pos': {'NOUN', 'VERB', 'PROPN'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 1.0, 'q': ['school', 'nursing', 'high'], 'pos_vec': [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'pos': {'ADV', 'NOUN'}} \n",
      "\n",
      "{'score': 0.82623465712856, 'base_score': 0.0, 'q': ['average', 'salary', 'physician', '2014', 'assistant', 'pay', 'vs', 'best', 'jobs', 'assistants', '97,280', 'nurse', 'practitioners', '2013', 'doctors', 'paid', 'fact', 'physicianâ'], 'pos_vec': [0, 0, 0, 8, 0, 0, 3, 2, 3, 1, 1, 0, 0, 0, 0], 'pos': {'PROPN', 'NUM', 'ADP', 'VERB', 'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 0.7043638493171503, 'base_score': 0.0, 'q': ['physician', 'difference', 'assistant', 'assistants', 'nps', 'variety', 'pas', 'patient', 'asks', 'nurse', 'differences', 'practitioner', 'main', 'occupations', 'training', 'involved', 'practitioners'], 'pos_vec': [0, 0, 0, 11, 0, 0, 1, 3, 0, 0, 2, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB', 'PROPN'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.0, 'q': ['goats', 'different', 'breeds', 'miniature'], 'pos_vec': [0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.42985934992609853, 'q': ['started', 'farming', 'neolithic', 'revolution', 'people', 'important', 'new', 'time'], 'pos_vec': [0, 0, 0, 3, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB'}} \n",
      "\n",
      "{'score': 0.7601875334318686, 'base_score': 0.0, 'q': ['macromolecules', 'biological', 'classes', 'types'], 'pos_vec': [0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'PROPN'}} \n",
      "\n",
      "{'score': 0.7601875334318686, 'base_score': 0.23981246656813146, 'q': ['international', 'linguistics', 'olympiad', 'iol', 'language', 'newest', 'group', 'thirteen', 'science', 'olympiads', 'abbreviation', 'linguistic', 'moscow', 'russia', '1988'], 'pos_vec': [0, 0, 0, 1, 0, 0, 1, 1, 2, 0, 10, 0, 0, 0, 0], 'pos': {'PROPN', 'NUM', 'VERB', 'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 0.7601875334318686, 'base_score': 0.0, 'q': ['linguistics', 'applied', 'language', 'early', 'field', 'theoretical', 'including', 'problems', 'real', 'world', 'concerned', 'teaching'], 'pos_vec': [0, 0, 0, 5, 0, 0, 4, 2, 0, 0, 1, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB', 'PROPN'}} \n",
      "\n",
      "{'score': 0.3800937667159343, 'base_score': 0.0, 'q': ['energy', 'forms', '1', 'kinetic', '2', 'potential', '3', 'gravitational', '4'], 'pos_vec': [0, 0, 0, 4, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0], 'pos': {'NUM', 'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 0.7601875334318686, 'base_score': 0.0, 'q': ['energy', 'mechanical', 'motion', 'position', 'acquired', 'objects', 'work', 'known', 'door', 'hands', 'kinetic', 'potential'], 'pos_vec': [0, 0, 0, 5, 0, 0, 1, 3, 0, 0, 3, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB', 'PROPN'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.0, 'q': ['energy', 'chemical', 'transform', '7', 'main', 'form', 'potential', 'type', 'comes', 'bonds', 'atoms', 'molecules', 'home', 'substance', 'results', 'reaction', 'called'], 'pos_vec': [0, 0, 0, 9, 0, 0, 2, 4, 1, 0, 1, 0, 0, 0, 0], 'pos': {'PROPN', 'NUM', 'VERB', 'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 0.8637574337885663, 'base_score': 0.0, 'q': ['uranus', 'size'], 'pos_vec': [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 0.3333333333333333, 'base_score': 0.0, 'q': ['pepper', 'spices', 'common', 'spice', 'yellow', 'middle', 'ages', 'mixture', 'indian', 'duck'], 'pos_vec': [0, 0, 0, 5, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.0, 'q': ['farming', 'beef', 'involves'], 'pos_vec': [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], 'pos': {'NOUN', 'VERB', 'PROPN'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.0, 'q': ['whale', 'orca', 'killer', 'known', 'including', 'whales', 'orcinus', 'rarely', 'referred', 'toothed', 'commonly'], 'pos_vec': [0, 0, 0, 3, 0, 0, 2, 3, 0, 0, 1, 0, 2, 0, 0], 'pos': {'PROPN', 'ADV', 'VERB', 'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.0, 'q': ['diet', 'grains', 'images', 'balanced', 'important', 'healthy', 'carbohydrates', 'supply', 'complex', 'proteins', 'fats', 'vitamins', 'minerals', 'recommended', 'total'], 'pos_vec': [0, 0, 0, 9, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB'}} \n",
      "\n",
      "{'score': 1.0, 'base_score': 0.3800937667159343, 'q': ['dairy', 'cancers', 'products', 'diet', 'consumption', 'linked', 'risk', 'milk', 'necessary', 'fact', 'harmful', 'health', 'consume', 'healthful', 'fat', 'including', 'saturated', 'conclusions', 'best'], 'pos_vec': [0, 0, 0, 8, 0, 0, 3, 4, 0, 0, 3, 0, 1, 0, 0], 'pos': {'PROPN', 'ADV', 'VERB', 'ADJ', 'NOUN'}} \n",
      "\n",
      "{'score': 0.3800937667159343, 'base_score': 0.0, 'q': ['hardware', 'mainframes', 'linux', 'virtualization', 'servers', 'ibm', 'z', 'search', 'desktop', 'tracker', 'file', 'recoll', 'open', 'source', 'work'], 'pos_vec': [0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 9, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'PROPN'}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for qid in cat1:\n",
    "    perfect_query = get_perfect_query(qid, train_qrels, es, index, 'trec2019_stem', pos_vocab)\n",
    "    print(perfect_query,\"\\n\")\n",
    "    cat1[qid]['perfect_query'] = perfect_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter query based on nearest neighbor perfect query\n",
    "For each query that falls in category 1, find the nearests neighbor in the cat1 dictionary and look at its perfect query. We can now filter any new query based on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ', 'NOUN', 'PROPN', 'VERB'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid = '1_1'\n",
    "q = ' '.join(evaluator.analyzer(es, index['1_1']['text'], 'trec2019_stem'))\n",
    "_, pos = pos_parser(q, pos_vocab)\n",
    "nb = knn(get_pos_counts(pos, pos_vocab), cat1, qid, 3)\n",
    "pos_filter = []\n",
    "for n in nb: # n=qid\n",
    "    pos_filter = pos_filter + list(cat1[n]['perfect_query']['pos'])\n",
    "pos_filter = set(pos_filter)\n",
    "pos_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: what is a physician's assistant\n",
      "Parsed: ['physician', 'assistant']\n"
     ]
    }
   ],
   "source": [
    "q = ' '.join(evaluator.analyzer(es, index[qid]['text'], 'trec2019_stem'))\n",
    "parsed_query, pos = pos_parser(q, pos_filter)\n",
    "print(f'Original: {q}\\nParsed: {parsed_query}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm thinks \"what is a\" is unuseful data for this query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original score: 0.0\n",
      "Parsed score: 0.0\n"
     ]
    }
   ],
   "source": [
    "sres, srank, gt = evaluator.get_search_data(parsed_query, qid, train_qrels, es, 'trec2019_stem')\n",
    "score = utils.ndcg(srank, gt, k=3)\n",
    "base_score = cat1[qid]['perfect_query']['base_score']\n",
    "print(f'Original score: {base_score}\\nParsed score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still get 0 in score even though the query seems to search for the key part of the users intuition. If we look at the perfect query above for this one, we can see that the two best keywords in fact is ['physician', 'assistant'], but it needs some additional data in order to receive relevant ones. We should therefore try to expand our filtered query in some way.\n",
    "\n",
    "### Expand filtered query\n",
    "The strategy here is to fetch top 100 documents from a base retrieval for the query. We will then compute the top keywords from these documents based on our pos filter, and then expand the parsed query with the most important keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = es.search(index='trec2019_stem', q=q, _source=False, size=100)['hits']['hits']\n",
    "base_ret = {i[\"_id\"]:1 for i in search_results}\n",
    "_, kw_count = get_kw_stats(base_ret, es, 'trec2019_stem', pos_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query(kw, query, k):\n",
    "    # We need to stem the words so we don't add similar words\n",
    "    # Ex: assistants will not be added to query [physician, assistant]\n",
    "    _kw = [ps.stem(w) for w in kw]\n",
    "    _q = [ps.stem(w) for w in query]\n",
    "    expanded_q = query.copy()\n",
    "    for stemmed_term,  term in zip(_kw, kw):\n",
    "        if stemmed_term not in _q:\n",
    "            expanded_q.append(term)\n",
    "    return expanded_q[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['physician', 'assistant', 'healthcare', 'professionals', 'educated']\n"
     ]
    }
   ],
   "source": [
    "expanded_q = expand_query(kw_count, parsed_query, len(parsed_query)+3)\n",
    "print(expanded_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original score: 0.0\n",
      "Parsed score: 0.0\n"
     ]
    }
   ],
   "source": [
    "sres, srank, gt = evaluator.get_search_data(expanded_q, qid, train_qrels, es, 'trec2019_stem')\n",
    "score = utils.ndcg(srank, gt, k=3)\n",
    "base_score = cat1[qid]['perfect_query']['base_score']\n",
    "print(f'Original score: {base_score}\\nParsed score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expansion technique did not work for this example.\n",
    "### Compare expansion vs no expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_scores = []\n",
    "base_scores = []\n",
    "expanded_scores = {k:[] for k in range(1,21)}\n",
    "for qid in cat1:\n",
    "    _q = ' '.join(evaluator.analyzer(es, index[qid]['text'], 'trec2019_stem'))\n",
    "    _, pos = pos_parser(_q, pos_vocab)\n",
    "    nb = knn(get_pos_counts(pos, pos_vocab), cat1, qid, 3)\n",
    "    pos_filter = []\n",
    "    for n in nb: # n=qid\n",
    "        pos_filter = pos_filter + list(cat1[n]['perfect_query']['pos'])\n",
    "    pos_filter = set(pos_filter)\n",
    "    q = ' '.join(evaluator.analyzer(es, index[qid]['text'], 'trec2019_stem'))\n",
    "    parsed_query, pos = pos_parser(q, pos_filter)\n",
    "    \n",
    "    sres, srank, gt = evaluator.get_search_data(parsed_query, qid, train_qrels, es, 'trec2019_stem')\n",
    "    score = utils.ndcg(srank, gt, k=3)\n",
    "    base_score = cat1[qid]['perfect_query']['base_score']\n",
    "    # Expand query (test with expanding size k=1,..,20)\n",
    "    search_results = es.search(index='trec2019_stem', q=q, _source=False, size=100)['hits']['hits']\n",
    "    base_ret = {i[\"_id\"]:1 for i in search_results}\n",
    "    _, kw_count = get_kw_stats(base_ret, es, 'trec2019_stem', pos_filter)\n",
    "    expanded_q = {k: expand_query(kw_count, parsed_query, len(parsed_query)+k) for k in range(1,21)}\n",
    "    for k, v in expanded_q.items():\n",
    "        sres, srank, gt = evaluator.get_search_data(v, qid, train_qrels, es, 'trec2019_stem')\n",
    "        expanded_score = utils.ndcg(srank, gt, k=3)\n",
    "        expanded_scores[k].append(expanded_score)\n",
    "    \n",
    "    parsed_scores.append(score)\n",
    "    base_scores.append(base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base scores: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.42985934992609853, 0.0, 0.23981246656813146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3800937667159343, 0.0]\n",
      "Average: 0.10248827916050822\n",
      "\n",
      "Parsed scores: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6199062332840657, 0.23981246656813146, 0.0, 0.7601875334318686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6199062332840657, 0.3800937667159343, 0.3800937667159343, 0.0]\n",
      "Average: 0.2\n",
      "\n",
      "Average expanded score for k=1 : 0.10350703250369508\n",
      "Average expanded score for k=2 : 0.09751172083949179\n",
      "Average expanded score for k=3 : 0.08552109751108522\n",
      "Average expanded score for k=4 : 0.07850703250369508\n",
      "Average expanded score for k=5 : 0.06300937667159343\n",
      "Average expanded score for k=6 : 0.06300937667159343\n",
      "Average expanded score for k=7 : 0.0665164091752885\n",
      "Average expanded score for k=8 : 0.0665164091752885\n",
      "Average expanded score for k=9 : 0.0665164091752885\n",
      "Average expanded score for k=10 : 0.0665164091752885\n",
      "Average expanded score for k=11 : 0.0665164091752885\n",
      "Average expanded score for k=12 : 0.0665164091752885\n",
      "Average expanded score for k=13 : 0.0665164091752885\n",
      "Average expanded score for k=14 : 0.07850703250369508\n",
      "Average expanded score for k=15 : 0.07850703250369508\n",
      "Average expanded score for k=16 : 0.07850703250369508\n",
      "Average expanded score for k=17 : 0.07850703250369508\n",
      "Average expanded score for k=18 : 0.07850703250369508\n",
      "Average expanded score for k=19 : 0.08450234416789836\n",
      "Average expanded score for k=20 : 0.08450234416789836\n"
     ]
    }
   ],
   "source": [
    "avg_parsed = sum(parsed_scores)/len(parsed_scores)\n",
    "avg_base = sum(base_scores)/len(base_scores)\n",
    "print(f'Base scores: {base_scores}\\nAverage: {avg_base}')\n",
    "print(f'\\nParsed scores: {parsed_scores}\\nAverage: {avg_parsed}\\n')\n",
    "for k, v in expanded_scores.items():\n",
    "    avg_expanded = sum(v)/len(v)\n",
    "    print(f'Average expanded score for k={k} : {avg_expanded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query expansion technique does not improve the score for the examples we have here. We can see that the score declines as we expand the parsed query with more terms. The parsed term technique did however almost double the original score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with a new unknown query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: What is a real-time database?\n",
      "3 nearest neighbors\n",
      "what are the main breeds of goat\n",
      "what was the neolithic revolution\n",
      "what are the different types of macromolecules\n"
     ]
    }
   ],
   "source": [
    "original_q = test_topics[58-31]['turn'][0]['raw_utterance']\n",
    "qid =  test_topics[58-31]['turn'][0]['qid']\n",
    "q = ' '.join(evaluator.analyzer(es, original_q, 'trec2019_stem'))\n",
    "_, pos = pos_parser(q, pos_vocab)\n",
    "nb = knn(get_pos_counts(pos, pos_vocab), cat1, k=3)\n",
    "print(f'Original: {original_q}')\n",
    "print(\"3 nearest neighbors\")\n",
    "for n in nb:\n",
    "    print(index[n][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADJ', 'NOUN', 'VERB', 'PROPN'}\n"
     ]
    }
   ],
   "source": [
    "pos_filter = []\n",
    "for n in nb: # n=qid\n",
    "    pos_filter = pos_filter + list(cat1[n]['perfect_query']['pos'])\n",
    "pos_filter = set(pos_filter)\n",
    "print(pos_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter seems makes sense since the query asks for information based on numerical data. Lets see how the algorithm parses the original query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: What is a real-time database?\n",
      "['real', 'time', 'database']\n"
     ]
    }
   ],
   "source": [
    "parsed_query, pos = pos_parser(q, pos_filter)\n",
    "print(f'Original: {original_q}')\n",
    "print(parsed_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base score: 0.4649296749630493\n",
      "Parsed score: 0.5248827916050821\n"
     ]
    }
   ],
   "source": [
    "sres, srank, gt = evaluator.get_search_data(parsed_query, qid, test_qrels, es, 'trec2019_stem')\n",
    "score = utils.ndcg(srank, gt, k=3)\n",
    "sres, srank, gt = evaluator.get_search_data(q, qid, test_qrels, es, 'trec2019_stem')\n",
    "base_score = utils.ndcg(srank, gt, k=3)\n",
    "print(f'Base score: {base_score}\\nParsed score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm was able to clean the original query and improve the base score for this example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the algorithm for category 1 improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is throat cancer?(1.0) -> ['throat', 'cancer'](1.0)\n",
      "What are the different types of sharks?(0.20663541109468855) -> ['different', 'types', 'sharks'](0.20663541109468855)\n",
      "Tell me about the Neverending Story film.(0.06377673039867192) -> ['tell', 'neverending', 'story', 'film'](0.06377673039867192)\n",
      "Tell me about the Bronze Age collapse.(0.09502344167898358) -> ['tell', 'bronze', 'age', 'collapse'](0.21492967496304927)\n",
      "What other factors led to a breakdown of trade?(0.0) -> ['other', 'factors', 'led', 'breakdown', 'trade'](0.0)\n",
      "What was the Stanford Experiment?(0.4400468833579672) -> ['stanford', 'experiment'](0.3450234416789836)\n",
      "What were the similarities and differences between the studies?(0.0) -> ['similarities', 'differences', 'between', 'studies'](0.0)\n",
      "What are the origins of popular music? (0.0) -> ['origins', 'popular', 'music'](0.0)\n",
      "How was Netflix started? (0.0) -> ['netflix', 'started'](0.0)\n",
      "When did Netflix shift from DVDs to a streaming service?(0.20216745220099608) -> ['when', 'netflix', 'shift', 'dvds', 'streaming', 'service'](0.16486045649916994)\n",
      "Describe it’s subscriber growth over time.(0.0) -> ['describe', '’s', 'subscriber', 'growth', 'time'](0.0)\n",
      "What was the first artificial satellite?(0.8450234416789836) -> ['first', 'artificial', 'satellite'](0.8450234416789836)\n",
      "How do navigation systems work?(0.0) -> ['navigation', 'systems', 'work'](0.0)\n",
      "What is worth seeing in Washington D.C.?(0.0799374888560438) -> ['worth', 'seeing', 'washington', 'd.c'](0.0)\n",
      "Why is the National Air and Space Museum important?(0.5207510959502315) -> ['why', 'national', 'air', 'space', 'museum', 'important'](0.5207510959502315)\n",
      "What is a DC half smoke?(0.0) -> ['dc', 'half', 'smoke'](0.0)\n",
      "What is Darwin’s theory in a nutshell?(0.28507032503695073) -> ['darwin', '’s', 'theory', 'in', 'nutshell'](0.3450234416789836)\n",
      "Compare and contrast microevolution and macroevolution.(0.9049765583210164) -> ['compare', 'contrast', 'microevolution', 'macroevolution'](0.9049765583210164)\n",
      "What is a real-time database?(0.4649296749630493) -> ['real', 'time', 'database'](0.5248827916050821)\n",
      "What are the advantages of real-time processing?(0.23981246656813146) -> ['advantages', 'real', 'time', 'processing'](0.4400468833579672)\n",
      "Which weekend sports have the most injuries?(0.09502344167898358) -> ['weekend', 'sports', 'most', 'injuries'](0.09502344167898358)\n",
      "Who are The Avengers?(0.11245065757013885) -> ['avengers'](0.2958497808099537)\n",
      "What is the relationship of Spider-Man to the team?(0.0) -> ['relationship', 'spider', 'man', 'team'](0.0)\n",
      "What is an important team in the DC universe? (0.5701406500739015) -> ['important', 'team', 'in', 'dc', 'universe'](0.5701406500739015)\n",
      "Tell me about the origins of the Justice League.(0.0) -> ['tell', 'origins', 'justice', 'league'](0.20663541109468855)\n",
      "Why is blood red?(0.09502344167898358) -> ['blood', 'red'](0.0)\n",
      "What foods contain high levels of iron?(0.0) -> ['foods', 'contain', 'high', 'levels', 'iron'](0.0)\n",
      "What is cuisine is Emilia-Romagna famous for?(0.4049765583210164) -> ['cuisine', 'emilia', 'romagna', 'famous'](0.4049765583210164)\n",
      "Tell me about cooking schools and classes.(0.0) -> ['tell', 'cooking', 'schools', 'classes'](0.10108372610049804)\n",
      "Describe the traditional process for making balsamic vinegar?(0.5599531166420328) -> ['describe', 'traditional', 'process', 'making', 'balsamic', 'vinegar'](0.5599531166420328)\n",
      "What is the history of tagliatelle al ragu bolognese?(0.5950234416789836) -> ['history', 'of', 'tagliatelle', 'al', 'ragu', 'bolognese'](0.5950234416789836)\n",
      "How do you sleep after jet lag?(0.3800937667159343) -> ['how', 'sleep', 'jet', 'lag'](0.3800937667159343)\n",
      "Why do turkey and Turkey share the same name?(0.0) -> ['turkey', 'turkey', 'share', 'same', 'name'](0.1833991232398149)\n",
      "Why did Ben Franklin want it to be the national symbol?(0.2754115523761867) -> ['ben', 'franklin', 'want', 'national', 'symbol'](0.41311732856428)\n",
      "What's the difference between soup and stew?(0.4377467121493058) -> ['difference', 'soup', 'stew'](0.1833991232398149)\n",
      "What is the keto diet?(0.0) -> ['keto', 'diet'](0.0)\n",
      "What is taught in sociology?(0.5701406500739015) -> ['taught', 'sociology'](0.5701406500739015)\n",
      "What is the main contribution of Auguste Comte?(0.4049765583210164) -> ['main', 'contribution', 'of', 'auguste', 'comte'](0.42985934992609853)\n",
      "What are modern examples of conflict theory?(0.19004688335796716) -> ['modern', 'examples', 'conflict', 'theory'](0.19004688335796716)\n"
     ]
    }
   ],
   "source": [
    "base_scores = []\n",
    "parsed_scores = []\n",
    "total = 0\n",
    "for topic in test_topics:\n",
    "    for turn in topic['turn']:\n",
    "        qid = turn['qid']\n",
    "        _qrels = utils.get_qrels(qid, test_qrels)\n",
    "        if not _qrels: # Only include turns with labeled relevancy\n",
    "            continue\n",
    "        total += 1\n",
    "        original_query = turn['raw_utterance']\n",
    "        q = ' '.join(evaluator.analyzer(es, original_query, 'trec2019_stem'))\n",
    "        txt, pos = pos_parser(q, pos_vocab)\n",
    "        pos_vec = get_pos_counts(pos, pos_vocab)\n",
    "        cat = get_category(pos)\n",
    "        if turn['number'] == 1 or cat==1:\n",
    "            nb = knn(get_pos_counts(pos, pos_vocab), cat1, k=3)\n",
    "            pos_filter = []\n",
    "            for n in nb: # n=qid\n",
    "                pos_filter = pos_filter + list(cat1[n]['perfect_query']['pos'])\n",
    "            pos_filter = set(pos_filter)\n",
    "            parsed_query, pos = pos_parser(q, pos_filter)\n",
    "            \n",
    "            sres, srank, gt = evaluator.get_search_data(parsed_query, qid, test_qrels, es, 'trec2019_stem')\n",
    "            if srank is None:\n",
    "                continue\n",
    "            score = utils.ndcg(srank, gt, k=3)\n",
    "            sres, srank, gt = evaluator.get_search_data(q, qid, test_qrels, es, 'trec2019_stem')\n",
    "            if srank is None:\n",
    "                continue\n",
    "            base_score = utils.ndcg(srank, gt, k=3)\n",
    "            print(f'{original_query}({base_score}) -> {parsed_query}({score})')\n",
    "            base_scores.append(base_score)\n",
    "            parsed_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 of 173 fell into category 2\n",
      "Average base score: 0.25741431796779657\n",
      "Average parsed score: 0.2757608276601204\n"
     ]
    }
   ],
   "source": [
    "avg_base = sum(base_scores)/len(base_scores)\n",
    "avg_parse = sum(parsed_scores)/len(parsed_scores)\n",
    "print(f'{len(parsed_scores)} of {total} fell into category 2')\n",
    "print(f'Average base score: {avg_base}\\nAverage parsed score: {avg_parse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm improved the original score by 0.0183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category 2\n",
    "Most of the items could levearge information from the previous context of the conversation. We will try to do this in the algorithm for category 2.\n",
    "## Reverse engineer perfect queries for category 2\n",
    "Store results in the cat2 dictionary. We will use pos vectors for perfect queries in the algorithm later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa physician assistant educational requirements order certified graduate program accredited assistants required orthopedic nurse practitioner opa => base: 0.0 => score: 0.8983537904952533\n",
      "resident tuition cost program => base: 0.0 => score: 0.7601875334318686\n",
      "physician salary average assistant assistantâ => base: 0.0 => score: 1.0\n",
      "average salary nurse practitioners physician assistants hour 2011 => base: 0.0 => score: 1.0\n",
      "assistant physician medical supervision => base: 0.0 => score: 1.0\n",
      "nurse practitioner years => base: 0.0 => score: 0.3800937667159343\n",
      "goat boer dutch => base: 0.6199062332840657 => score: 1.0\n",
      "goat meat boer highly breeds goats generally productive breed originated south s considered slow maturing good trait => base: 0.2754115523761867 => score: 1.0\n",
      "goat dairy meat goats breed spanish good fiber breeds angora generally milk production profitable like small => base: 0.0 => score: 0.7043638493171503\n",
      "goat boer dutch => base: 1.0 => score: 1.0\n",
      "pygmy goat called classes pedigree goats africa breed pygmies bucks pets neuter => base: 0.0 => score: 0.6199062332840657\n",
      "fiber angora goat length shades know fine bred goats produce cashmere milk => base: 0.0 => score: 1.0\n",
      "goats milk produce goat pygmy fun breeds angora generally meat production profitable like => base: 0.0 => score: 1.0\n",
      "goats cattle land support 2 acre available productivity poor raising => base: 0.0 => score: 0.7601875334318686\n",
      "meat united states raising goats profitable small => base: 0.0 => score: 0.82623465712856\n",
      "bc neolithic revolution time people world changed lifestyle hunting lived beings => base: 0.0 => score: 0.82623465712856\n",
      "started farming neolithic revolution people important new time technologies domestication reasons according harland => base: 0.0 => score: 0.8637574337885663\n",
      "stage began people invented second period neolithic era agriculture passing barbarity stone age art => base: 0.0 => score: 0.8637574337885663\n",
      "stone tools neolithic began read latest news age period 6,000 years ago materials shelters people development pottery agriculture paleolithic => base: 0.0 => score: 0.5681212831057167\n",
      "new british isles mesolithic period european => base: 0.0 => score: 1.0\n",
      "classical age antiquity period ad east ancient 600 limassol culture early district neolithic => base: 0.0 => score: 0.7601875334318686\n",
      "palaeolithic upper stone development middle period literally old age ancient cultural level human humans world history significant migration end ice => base: 0.0 => score: 1.0\n",
      "caves paleolithic number => base: 0.0 => score: 1.0\n",
      "carbohydrates functions carbohydrate monosaccharides saccharides abundant class store energy found complex simple sugars fructose => base: 0.0 => score: 1.0\n",
      "sugars carbohydrates honey contains => base: 0.0 => score: 1.0\n",
      "sugars carbohydrates simple form carbon hydrogen oxygen include starches cellulose compounds => base: 0.0 => score: 0.6199062332840657\n",
      "carbohydrates starches => base: 0.0 => score: 0.3800937667159343\n",
      "lipids fats molecules hydrogen oxygen carbohydrates elements carbon soluble hydrocarbons living cells non water polar environments important lipid => base: 0.0 => score: 0.7601875334318686\n",
      "lipids functions body fats fat soluble storage common different perform biological compounds triglycerides serve reserve energy important component cell membranes => base: 0.0 => score: 0.7601875334318686\n",
      "important body lipid lipids types include triglycerides => base: 0.0 => score: 0.7601875334318686\n",
      "common lipids soluble compounds organic structure occurring class fats phospholipids contain share => base: 0.0 => score: 1.0\n",
      "lipids carbohydrates 4 release kcal gram function cellular signaling sugars form polymers important ones difference => base: 0.0 => score: 0.7601875334318686\n",
      "individual setup differs science olympiads program contains team contests contest consists 5 linguistics knowledge => base: 0.0 => score: 0.82623465712856\n",
      "international linguistics olympiad iol language newest group thirteen science olympiads abbreviation individual setup differs program contains => base: 0.0 => score: 1.0\n",
      "individual setup differs => base: 0.0 => score: 0.43187871689428314\n",
      "energy atp potential work muscle contraction produce app biological kinetic stored types motion moving electricity water flashlight food => base: 0.0 => score: 1.0\n",
      "energy mechanical motion position acquired objects work known object conservative forces potential kinetic constant increase changed ability => base: 0.0 => score: 1.0\n",
      "mechanical energy example power football flying air => base: 0.0 => score: 0.8637574337885663\n",
      "energy mechanical sound => base: 1.0 => score: 1.0\n",
      "energy mechanical present => base: 0.0 => score: 0.7601875334318686\n",
      "energy potential stored form object types kinetic => base: 0.0 => score: 1.0\n",
      "energy respiration foods => base: 0.0 => score: 1.0\n",
      "earth uranus pale times makes spin => base: 0.0 => score: 1.0\n",
      "orbit uranus discovery takes => base: 0.0 => score: 0.3800937667159343\n",
      "uranus planet axis solar system billion years tilt extreme orbit encounter planets sun direction => base: 0.0 => score: 0.920303207764292\n",
      "rotation orbital uranus => base: 0.0 => score: 1.0\n",
      "uranus neptune planets unlike giant extreme tilt causes earth seasons years different starters season => base: 0.0 => score: 1.0\n",
      "uranus neptune planets twin earth venus â outer considered => base: 0.0 => score: 0.82623465712856\n",
      "neptune methane uranus atmospheric => base: 0.11990623328406573 => score: 0.3800937667159343\n",
      "spices ground flavor form herbs leaf seed differences add taste food time confused tropical chefs use terms interchangeably originate => base: 0.0 => score: 0.920303207764292\n",
      "powder lemon ground sour amchur dried sweet cooling effect good english known spice spices blend oriental food stores shops => base: 0.0 => score: 0.8154648767857287\n",
      "spice cinnamon tree bark rosemary shrub mustard seed garlic bulb sassafras source spices flavors texturizers foods oil => base: 0.0 => score: 1.0\n",
      "spice mixture indian bengali panch phoron powder => base: 0.0 => score: 0.6199062332840657\n",
      "leaves cardamom masala => base: 0.0 => score: 1.0\n",
      "turmeric 2 curcumin arthritis plant india => base: 0.0 => score: 0.7601875334318686\n",
      "turmeric drinks benefits curcumin body help water glass morning drink warm blood fresh anti oxidants winter dried peeling => base: 0.0 => score: 0.8983537904952533\n",
      "crocus saffron flowers spice flower takes 165 gram stigma female spices expensive delicately flavored adds golden stigmas yellow orange => base: 0.0 => score: 0.7601875334318686\n",
      "breeds cattle dairy milk => base: 0.0 => score: 0.5508231047523734\n",
      "milk pounds holstein => base: 0.0 => score: 1.0\n",
      "cows cattle fed => base: 0.0 => score: 1.0\n",
      "angus cattle black beef 1 medium sized polled => base: 0.0 => score: 1.0\n",
      "cow hay need calf => base: 0.0 => score: 1.0\n",
      "cancer smoking lung risk smokers commonly heart => base: 0.0 => score: 0.5\n",
      "cancer smoking cigarette cause 1 => base: 0.0 => score: 0.3800937667159343\n",
      "cigarettes cigarette electronic nicotine smoking smokers copd devices look similar addictive makes drugs addiction like herbal => base: 0.43187871689428314 => score: 0.6478180753414247\n",
      "nicotine replacement products help withdrawal cigarette smoking niquitin range designed source patch available hour therapy => base: 0.3800937667159343 => score: 0.7601875334318686\n",
      "patch nicotine level => base: 0.0 => score: 0.82623465712856\n",
      "difficult found cold turkey term studies method quitters ex smokers said means use reducing smoking quitting completely stop => base: 0.0 => score: 1.0\n",
      "symptoms nicotine withdrawal irritability anxiety depression weight difficulty concentrating usually => base: 0.0 => score: 1.0\n",
      "whales killer orcinus species orca called orcas considered => base: 0.7601875334318686 => score: 0.7601875334318686\n",
      "killer whale whales source => base: 0.0 => score: 0.5\n",
      "whales eat large animals orcas called killer active hunters 2 fish marine deer hunt dolphins seals => base: 0.0 => score: 0.7601875334318686\n",
      "killer dolphins whale orca whales scientific orcinus source common causes hunt => base: 0.0 => score: 0.6199062332840657\n",
      "world creatures predators humans orca orcas sea animal amazing killer whales savage western cultures historically feared => base: 0.0 => score: 0.8637574337885663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whales whale seen coast summer san year round california february watching new zealand kaikoura hauraki gulf seattle orca juan incredible => base: 0.0 => score: 1.0\n",
      "whales whale seen coast summer => base: 0.0 => score: 1.0\n",
      "captivity killer whales practice => base: 0.0 => score: 0.5508231047523734\n",
      "diet need balanced high people sugar => base: 0.0 => score: 1.0\n",
      "vitamins dietary recommendations beneficial men women womenâ s bodies different needs diet supplements healthy vitamin nutrients health best food balanced => base: 0.0 => score: 0.82623465712856\n",
      "acid fat ice cream high list things dairy downside saturated want lose weight foods avoid pregnancy harm => base: 0.0 => score: 0.6229422381190666\n",
      "fiber soluble â s => base: 0.0 => score: 0.43187871689428314\n",
      "fiber consume increase => base: 0.0 => score: 1.0\n",
      "windows virtual linux wine software machine run machines s t api applications application project available microsoft => base: 0.0 => score: 1.0\n",
      "linux boot prefer windows reason people dual loader called grub microsoft studies tco server => base: 0.0 => score: 0.7601875334318686\n",
      "windows operating devices android ios popular system categories use linux computers pre microsoft said large 1999 non installed => base: 0.0 => score: 1.0\n",
      "rpm software linux use install root package manager automatic acces scanning mint => base: 0.34753068574288 => score: 0.82623465712856\n",
      "python install version macports idle numpy pygame download downloading gcc => base: 0.0 => score: 1.0\n",
      "file share => base: 0.0 => score: 0.6478180753414247\n"
     ]
    }
   ],
   "source": [
    "for qid in cat2:\n",
    "    perfect_query = get_perfect_query(qid, train_qrels, es, index, 'trec2019_stem', pos_vocab)\n",
    "    q = ' '.join(perfect_query['q'])\n",
    "    bs = perfect_query['base_score']\n",
    "    s = perfect_query['score']\n",
    "    print(f'{q} => base: {bs} => score: {s}')\n",
    "    cat2[qid]['perfect_query'] = perfect_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "The query rewriter algorithm expands the original parsed query with whatever tokens from previous history it thinks is most important. The tokens must have a pos-tag within the pos_filter that gets created by looking at the pos-tags of perfect queries from 3 nearest neighbors (most similar query from cat2). The algorithm will expand the original query by every possible combination of tokens until it reaches 25k combinations. It will then only add NOUN, PROPN and ADV tokens. It will compute the euclidean distance between the pos vector of each combination and the pos vector of the perfect query. All queries with maximum 0.5 distance compared to the top score will be filtered out. We then compute the average distance of the remaining queries and returns the first one with average length (best scores among those with average length). We take the average length since expanded queries tend to be both way too short and way too long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(q, q_pos, history, pos_filter, pos_vocab, pq):\n",
    "    #print('Original query ', q)\n",
    "    expanded_queries = [q.copy()]\n",
    "    expanded_queries_pos = [q_pos]\n",
    "    for h in history:\n",
    "        txt, pos = pos_parser(h, pos_filter)\n",
    "        for t, p in zip(txt, pos):\n",
    "            if len(expanded_queries) > 25000:\n",
    "                if p in ['NOUN', 'PROPN', 'ADV']:\n",
    "                    tmp = q.copy() + [t]\n",
    "                    tmp_p = q_pos.copy() + [p]\n",
    "                    expanded_queries.append(tmp)\n",
    "                    expanded_queries_pos.append(tmp_p)\n",
    "            else:\n",
    "                for ep, e in zip(expanded_queries_pos ,expanded_queries):\n",
    "                    if t not in e:\n",
    "                        tmp = e + [t]\n",
    "                        tmp_p = ep + [p]\n",
    "                        expanded_queries.append(tmp)\n",
    "                        expanded_queries_pos.append(tmp_p)\n",
    "    #print(f'{len(expanded_queries)} expanded')\n",
    "    pos_vecs  = [get_pos_counts(p, pos_vocab) for p in expanded_queries_pos]\n",
    "    dists = [euclidean_distance(pq['pos_vec'], pos_vec) for pos_vec in pos_vecs]\n",
    "    top_q = expanded_queries[np.argmin(dists)]\n",
    "    s = dists[np.argmin(dists)]\n",
    "    dists = [d for d in dists if (s-d) < .5]\n",
    "    avg_dists_l = sum([len(d) for d in expanded_queries])/len(expanded_queries)\n",
    "\n",
    "    for i in range(len(dists)):\n",
    "        l = len(expanded_queries[i])\n",
    "        #if l == round(avg_dists_l):\n",
    "        #    top_q = expanded_queries[i]\n",
    "        #break\n",
    "        if l > len(top_q) and (s-dists[i]) < .5:\n",
    "            top_q = expanded_queries[i]\n",
    "    top_p = expanded_queries_pos[np.argmin(dists)]\n",
    "\n",
    "    #print(\"Top query: \", top_q, \" pos \", top_p, \" score \", dists[np.argmin(dists)])\n",
    "    return top_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run algorithm on an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: what are some specific recommendations for women\n",
      "what is the best for fiber production\n",
      "what breed is good for meat\n",
      "are angora goats good for it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADJ', 'ADV', 'NOUN', 'PROPN', 'SCONJ', 'VERB'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid = '27_3'\n",
    "q = ' '.join(evaluator.analyzer(es, index[qid]['text'], 'trec2019_stem'))\n",
    "_, pos = pos_parser(q, pos_vocab)\n",
    "nb = knn(get_pos_counts(pos, pos_vocab), cat2, qid, 3)\n",
    "pos_filter = []\n",
    "print(f'Original: {q}')\n",
    "for n in nb: # n=qid\n",
    "    print(index[n]['text'])\n",
    "    pos_filter = pos_filter + list(cat2[n]['perfect_query']['pos'])\n",
    "pos_filter = set(pos_filter)\n",
    "pos_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the query based on the computed pos_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: what are some specific recommendations for women\n",
      "Parsed: ['specific', 'recommendations', 'women']\n"
     ]
    }
   ],
   "source": [
    "q = ' '.join(evaluator.analyzer(es, index[qid]['text'], 'trec2019_stem'))\n",
    "parsed_query, pos = pos_parser(q, pos_filter)\n",
    "print(f'Original: {q}\\nParsed: {parsed_query}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare parsed query with base query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original score: 0.0\n",
      "Parsed score: 0.0\n"
     ]
    }
   ],
   "source": [
    "sres, srank, gt = evaluator.get_search_data(parsed_query, qid, train_qrels, es, 'trec2019_stem')\n",
    "score = utils.ndcg(srank, gt, k=3)\n",
    "base_score = cat2[qid]['perfect_query']['base_score']\n",
    "print(f'Original score: {base_score}\\nParsed score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of them got 0 in score. This makes sense since previous information in the conversation is needed in order to retrieve relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what comprises a balanced diet', 'is it the same for men as well as women']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# History data for this conversation\n",
    "for topic in train_topics:\n",
    "    history = []\n",
    "    done = False\n",
    "    for turn in topic['turn']:\n",
    "        if turn['qid'] == qid:\n",
    "            done = True\n",
    "            break\n",
    "        txt = index[turn['qid']]['text']\n",
    "        _, pos = pos_parser(txt, pos_vocab)\n",
    "        cat = get_category(pos)\n",
    "        if cat == 3:\n",
    "            #print(\"####Topic shift. clean history\")\n",
    "            history = [txt]\n",
    "        else:\n",
    "            history.append(txt)\n",
    "    if done:\n",
    "        break\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only consider the most similar query's perfect query data when expanding the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 1.0, 'base_score': 0.0, 'q': ['fiber', 'angora', 'goat', 'length', 'shades', 'know', 'fine', 'bred', 'goats', 'produce', 'cashmere', 'milk'], 'pos_vec': [0, 0, 0, 5, 0, 0, 2, 2, 0, 0, 3, 0, 0, 0, 0], 'pos': {'ADJ', 'NOUN', 'VERB', 'PROPN'}}\n"
     ]
    }
   ],
   "source": [
    "pq = cat2[list(nb.keys())[0]]['perfect_query']\n",
    "print(pq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run algorithm and print new generated query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated new query: ['specific', 'recommendations', 'women', 'comprises', 'balanced', 'diet', 'same', 'men', 'as', 'well']\n"
     ]
    }
   ],
   "source": [
    "new_q = rewrite_query(parsed_query, pos, history, pos_filter, pos_vocab, pq)\n",
    "print(f'\\nGenerated new query: {new_q}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query seems to have added some useful tokens based on the context. Lets evaluate it against the base query with NDCG 3,100 and 1000 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base query NDCG@1000:  0.0 Base query NDCG@100:  0.0  Base query NDCG@3:  0.0\n",
      "Base query NDCG@1000:  0.42947 New query NDCG@100:  0.40035  New query NDCG@3:  0.34753\n"
     ]
    }
   ],
   "source": [
    "_, srank, gt = evaluator.get_search_data(index[qid]['text'], qid, train_qrels, es, 'trec2019_stem', size=1000)\n",
    "print('Base query NDCG@1000: ', utils.ndcg(srank, gt, k=1000),\n",
    "      'Base query NDCG@100: ', utils.ndcg(srank, gt, k=100),\n",
    "      \" Base query NDCG@3: \", utils.ndcg(srank, gt, k=3))\n",
    "\n",
    "_, srank, gt = evaluator.get_search_data(new_q, qid, train_qrels, es, 'trec2019_stem', size=1000)\n",
    "print('Base query NDCG@1000: ', round(utils.ndcg(srank, gt, k=1000),5),\n",
    "      'New query NDCG@100: ', round(utils.ndcg(srank, gt, k=100),5),\n",
    "      \" New query NDCG@3: \", round(utils.ndcg(srank, gt, k=3),5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new query did clearly improve the original search!\n",
    "\n",
    "### Check if the algorithm for category 2 improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is throat cancer?']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_history(qid, topics):\n",
    "    history = []\n",
    "    for topic in topics:\n",
    "        history = []\n",
    "        done = False\n",
    "        for turn in topic['turn']:\n",
    "            if turn['qid'] == qid:\n",
    "                done = True\n",
    "                break\n",
    "            txt = turn['raw_utterance']\n",
    "            _, pos = pos_parser(txt, pos_vocab)\n",
    "            cat = get_category(pos)\n",
    "            if cat == 3:\n",
    "                #print(\"####Topic shift. clean history\")\n",
    "                history = [txt]\n",
    "            else:\n",
    "                history.append(txt)\n",
    "        if done:\n",
    "            break\n",
    "    return history\n",
    "            \n",
    "#get_history('27_3')\n",
    "get_history('31_2', test_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic:  31\n",
      "Topic:  32\n",
      "Topic:  33\n",
      "Topic:  34\n",
      "Topic:  35\n",
      "Topic:  36\n",
      "Topic:  37\n",
      "Topic:  38\n",
      "Topic:  39\n",
      "Topic:  40\n",
      "Topic:  41\n",
      "Topic:  42\n",
      "Topic:  43\n",
      "Topic:  44\n",
      "Topic:  45\n",
      "Topic:  46\n",
      "Topic:  47\n",
      "Topic:  48\n",
      "Topic:  49\n",
      "Topic:  50\n",
      "Topic:  51\n",
      "Topic:  52\n",
      "Topic:  53\n",
      "Topic:  54\n",
      "Topic:  55\n",
      "Topic:  56\n",
      "Topic:  57\n",
      "Topic:  58\n",
      "Topic:  59\n",
      "Topic:  60\n",
      "Topic:  61\n",
      "Topic:  62\n",
      "Topic:  63\n",
      "Topic:  64\n",
      "Topic:  65\n",
      "Topic:  66\n",
      "Topic:  67\n",
      "Topic:  68\n",
      "Topic:  69\n",
      "Topic:  70\n",
      "Topic:  71\n",
      "Topic:  72\n",
      "Topic:  73\n",
      "Topic:  74\n",
      "Topic:  75\n",
      "Topic:  76\n",
      "Topic:  77\n",
      "Topic:  78\n",
      "Topic:  79\n",
      "Topic:  80\n"
     ]
    }
   ],
   "source": [
    "base_scores = []\n",
    "parsed_scores = []\n",
    "expanded_scores = []\n",
    "total = 0\n",
    "for topic in test_topics:\n",
    "    print('Topic: ', topic['number'])\n",
    "    for turn in topic['turn']:\n",
    "        qid = turn['qid']\n",
    "        _qrels = utils.get_qrels(qid, test_qrels)\n",
    "        if not _qrels: # Only include turns with labeled relevancy\n",
    "            continue\n",
    "        total += 1\n",
    "        original_query = turn['raw_utterance']\n",
    "        q = ' '.join(evaluator.analyzer(es, original_query, 'trec2019_stem'))\n",
    "        txt, pos = pos_parser(q, pos_vocab)\n",
    "        pos_vec = get_pos_counts(pos, pos_vocab)\n",
    "        cat = get_category(pos)\n",
    "        if turn['number'] != 1 and cat==2:\n",
    "            nb = knn(get_pos_counts(pos, pos_vocab), cat2, qid, 3)\n",
    "            pos_filter = []\n",
    "            for n in nb: # n=qid\n",
    "                pos_filter = pos_filter + list(cat2[n]['perfect_query']['pos'])\n",
    "            pos_filter = set(pos_filter)\n",
    "            parsed_query, pos = pos_parser(q, pos_filter)\n",
    "            \n",
    "            # Base score\n",
    "            _, srank, gt = evaluator.get_search_data(q, qid, test_qrels, es, 'trec2019_stem')\n",
    "            if srank is None:\n",
    "                continue\n",
    "            base_scores.append(utils.ndcg(srank, gt, k=3))\n",
    "            \n",
    "            # Parsed score\n",
    "            _, srank, gt = evaluator.get_search_data(parsed_query, qid, test_qrels, es, 'trec2019_stem')\n",
    "            if srank is None:\n",
    "                continue\n",
    "            parsed_scores.append(utils.ndcg(srank, gt, k=3))\n",
    "            \n",
    "            # Algorithm\n",
    "            history = get_history(qid, test_topics)\n",
    "            pq = cat2[list(nb.keys())[0]]['perfect_query']\n",
    "            new_q = rewrite_query(parsed_query, pos, history, pos_filter, pos_vocab, pq)\n",
    "            _, srank, gt = evaluator.get_search_data(new_q, qid, test_qrels, es, 'trec2019_stem')\n",
    "            if srank is None:\n",
    "                continue\n",
    "            expanded_scores.append(utils.ndcg(srank, gt, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 of 173 fell into category 2\n",
      "Average base score: 0.09823090556943129\n",
      "Average parsed score: 0.10958319759847135\n",
      "Average expanded score: 0.18114566757827463\n"
     ]
    }
   ],
   "source": [
    "avg_base = sum(base_scores)/len(base_scores)\n",
    "avg_parse = sum(parsed_scores)/len(parsed_scores)\n",
    "avg_expanded = sum(expanded_scores)/len(expanded_scores)\n",
    "print(f'{len(parsed_scores)} of {total} fell into category 2')\n",
    "print(f'Average base score: {avg_base}\\nAverage parsed score: {avg_parse}\\nAverage expanded score: {avg_expanded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm doubled the ndcg@3 score by expanding the query with tokens it thinks is useful! This is results from the test data, meaning all queries are unknown and we only compare it against similar queries from the training data and their perfect reverse engineered queries. We can further improve the score by reranking these results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
